model:
  num_classes: 80
  backbone: cspdarknet53
  pretrained_backbone: True

  neck: FPN
  neck_config:
    out_channels: 256
    fuse_fn: sum

  head_config:
    width: 256
    depth: 3

  box_loss: GIoULoss
  box_multiplier: 16
  box_loss_weight: 5

  heatmap_prior: 0.01
  heatmap_loss_weight: 1

  # optimizer and scheduler
  optimizer_config:
    jit: true
    optimizer: AdamW
    lr: 0.00025               # 5e-4 for batch size 128
    weight_decay: 0.001
    norm_weight_decay: 0
    warmup_epochs: 5
    warmup_decay: 0.01

  # data
  train_data:
    batch_size: 32
    num_workers: 4
    img_dir: ../datasets/COCO/images/train2017
    ann_json: ../datasets/COCO/annotations/instances_train2017.json

    transforms:
      - name: HorizontalFlip
      - name: RandomResizedCrop
        init_args:
          height: 512
          width: 512
      - name: ColorJitter
        init_args:
          brightness: 0.4
          contrast: 0.4
          saturation: 0.4
      - name: Normalize
        init_args:
          mean: [0.5,0.5,0.5]
          std: [0.5,0.5,0.5]

  val_data:
    batch_size: 32
    num_workers: 4
    img_dir: ../datasets/COCO/images/val2017
    ann_json: ../datasets/COCO/annotations/instances_val2017.json
 
    transforms:
      - name: Resize
        init_args:
          height: 512
          width: 512
      - name: Normalize
        init_args:
          mean: [0.5,0.5,0.5]
          std: [0.5,0.5,0.5]

trainer:
  gpus: 2
  strategy: ddp_find_unused_parameters_false
  precision: 16
  benchmark: true
  sync_batchnorm: true
  max_epochs: 100

  logger:
    - class_path: pytorch_lightning.loggers.WandbLogger
      init_args:
        project: centernet
        log_model: true

  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val/mAP
        mode: max
