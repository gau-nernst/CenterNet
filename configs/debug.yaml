# this config file is for debug only
model:
  backbone:
    name: resnet18
    upsample_channels: [256, 128, 64]
    upsample_block:
      upsample_type: conv_transpose     # conv_transpose, bilinear, neareast
      conv_type: normal                 # normal, separable, dcn
      deconv_kernel: 4                  # only used with conv_transpose
      init_bilinear: True               # only used with conv_transpose
  
  num_classes: 80
  output_heads:
    other_heads: [size, offset]
    fill_bias: 
      heatmap: -2.19
      size: null
      offset: null
    loss_weights:
      size: 0.1
      offset: 1
    loss_functions:
      size: L1Loss      # a loss from torch.nn e.g. L1Loss, SmoothL1Loss
      offset: L1Loss

  optimizer:           # mmdetection
    name: SGD          # any optimizers from torch.optim
    params:
      lr: 0.02
      momentum: 0.9
      weight_decay: 0.0001

  lr_scheduler:
    name: OneCycleLR    # any lr_scheduler from torch.optim.lr_scheduler
    params:
      max_lr: 0.02

data:
  train:
    data_dir: datasets/COCO/train2017
    annotation_file: datasets/COCO/annotations/instances_train2017.json
    coco: True
    dataloader_params:
      batch_size: 4
      num_workers: 2
      shuffle: True
      pin_memory: True
    transforms:
      # augmentations used in CenterNet paper
      # https://github.com/xingyizhou/CenterNet/blob/master/src/lib/utils/image.py#L222
      # they also used PCA augmentation, but didn't mention in their paper
      - name: HorizontalFlip        # any transformations from Albumentation
        params:
          p: 0.5
      - name: RandomResizedCrop
        params:
          height: 512
          width: 512
      - name: ColorJitter
        params:
          brightness: 0.4
          contrast: 0.4
          saturation: 0.4

  validation:
    data_dir: datasets/COCO/val2017
    annotation_file: datasets/COCO/annotations/instances_val2017.json
    coco: True
    dataloader_params:
      batch_size: 4
      num_workers: 2
      shuffle: False
      pin_memory: True
    transforms:
      - name: Resize
        params:
          height: 512
          width: 512

trainer:
  params:
    gpus: 1
    precision: 16
    max_epochs: 1
    limit_train_batches: 0.01
    limit_val_batches: 0.05
    val_check_interval: 0.5
    benchmark: True
    gradient_clip_val: 35     # mmdetection

  logger:
    name: wandb         # tensorboard or wandb
    params:
      project: test
      log_model: True
